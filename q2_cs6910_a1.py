# -*- coding: utf-8 -*-
"""q2_cs6910_a1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qhSKwk8-gTtjwy0limyB6TbiS8U5LdBj
"""

import numpy as np
from keras.datasets import fashion_mnist
import matplotlib.pyplot as plt
from AF import Sigmoid, tanh, identity, ReLU, softmax
from fwd_prop import ForwardPropagation
from initialise_weights import InitialiseParams

(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

# Define class labels
class_labels = {
    0: 'T-shirt/top',
    1: 'Trouser',
    2: 'Pullover',
    3: 'Dress',
    4: 'Coat',
    5: 'Sandal',
    6: 'Shirt',
    7: 'Sneaker',
    8: 'Bag',
    9: 'Ankle boot'
}

class_num = 10

plt.figure(figsize=(10,10))
for i in range(class_num):

    idx = np.where(i == y_train)[0][0]
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(x_train[idx], cmap=plt.cm.binary)
    plt.xlabel(class_labels[y_train[idx]])
plt.show()

def train_val_split(X, y, val_size, random_state=None):
    if random_state is not None:
        np.random.seed(random_state)

    num_samples = X.shape[0]
    num_val_samples = int(num_samples * val_size)

    # Shuffle indices
    indices = np.arange(num_samples)
    np.random.shuffle(indices)

    # Split indices into train and test sets
    val_indices = indices[:num_val_samples]
    train_indices = indices[num_val_samples:]

    # Split data
    X_train, X_val = X[train_indices], X[val_indices]
    y_train, y_val = y[train_indices], y[val_indices]

    return X_train, X_val, y_train, y_val

x_train, x_val, y_train, y_val = train_val_split(x_train, y_train, val_size=0.1, random_state=2)
print("Done!")

print("Size of Training data:", x_train.shape)
print("Size of Validation data:", x_val.shape)

x_train_scaled = x_train/225.0
X_val_scaled = x_val/225
X_test_scaled = x_test/225

x_train_scaled = x_train_scaled.reshape(x_train_scaled.shape[0], x_train_scaled.shape[1]*x_train_scaled.shape[2]).T
X_val_scaled = X_val_scaled.reshape(X_val_scaled.shape[0], X_val_scaled.shape[1]*X_val_scaled.shape[2]).T
X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1]*X_test_scaled.shape[2]).T

# One-hot encoding the labels
def one_hot_encode(labels, num_classes):
    num_samples = len(labels)
    one_hot_labels = np.zeros((num_classes, num_samples))
    for i, label in enumerate(labels):
        one_hot_labels[label, i] = 1
    return one_hot_labels

y_train_one_hot = one_hot_encode(y_train, class_num)
y_val_one_hot = one_hot_encode(y_val, class_num)
y_test_one_hot = one_hot_encode(y_test, class_num)


num_layers, hidden_size, input_features, num_classes = 4, 25, 28*28, 10


initializer = InitialiseParams(num_layers, hidden_size, input_features, num_classes)
layer_dims = initializer.initialise_params()
parameters_random = initializer.random_ini(layer_dims)

activation_fn = ReLU()

forward_propagator = ForwardPropagation(parameters_random, activation_fn)
X = x_train_scaled  # Example input
AL, caches = forward_propagator.forward_propagation(X, layer_dims)

print("Output shape:", AL.shape)
print("Number of caches:", len(caches))

